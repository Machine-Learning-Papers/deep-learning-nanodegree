{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [09:38, 295KB/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe4d6de5128>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return x / 255\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    one_hot = np.zeros((len(x), 10))\n",
    "    for i in range(len(x)):\n",
    "        one_hot[i][x[i]] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    "If you're finding it hard to dedicate enough time for this course a week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) to build each layer, except \"Convolutional & Max Pooling\" layer.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    "If you would like to get the most of this course, try to solve all the problems without TF Layers.  Let's begin!\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,\n",
    "                          shape = [None, image_shape[0], image_shape[1], image_shape[2]],\n",
    "                          name = 'x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,\n",
    "                          shape = [None, n_classes],\n",
    "                          name = 'y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name = 'keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "Note: You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer.  You're free to use any TensorFlow package for all the other layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    # Input/Image\n",
    "    input = x_tensor\n",
    "    \n",
    "    # Weight and bias\n",
    "    weight = tf.Variable(tf.truncated_normal(\n",
    "        [conv_ksize[0], conv_ksize[1], x_tensor.get_shape().as_list()[-1], conv_num_outputs], stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    # Apply Convolution\n",
    "    conv_layer = tf.nn.conv2d(input, weight, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    # Add bias\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    # Apply activation function\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    # Apply maxpooling\n",
    "    conv_layer = tf.nn.max_pool(\n",
    "        conv_layer,\n",
    "        ksize=[1, pool_ksize[0], pool_ksize[1], 1],\n",
    "        strides=[1, pool_strides[0], pool_strides[1], 1],\n",
    "        padding='SAME')\n",
    "    return conv_layer \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    batch_size = x_tensor.get_shape().as_list()[0]# i tried as_list()[] \n",
    "    width = x_tensor.get_shape().as_list()[1]\n",
    "    height = x_tensor.get_shape().as_list()[2]\n",
    "    depth = x_tensor.get_shape().as_list()[3]\n",
    "\n",
    "    image_flat_size = width * height * depth\n",
    "\n",
    "    return tf.contrib.layers.flatten(x_tensor, [batch_size, image_flat_size])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer.\n",
    "\n",
    "Note: Activation, softmax, or cross entropy shouldn't be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weights = tf.Variable(tf.truncated_normal([x_tensor.get_shape().as_list()[1], num_outputs])) \n",
    "    mul = tf.matmul(x_tensor, weights, name='mul')\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    return tf.add(mul, bias)\n",
    "\n",
    "#     y = tf.add(mul, bias)\n",
    "#     fc = tf.contrib.layers.fully_connected(y, num_outputs)\n",
    "#     return fc\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_num_outputs = 10\n",
    "    conv_ksize = [2, 2]\n",
    "    conv_strides = [2, 2]\n",
    "    pool_ksize = [2, 2]\n",
    "    pool_strides = [2, 2]\n",
    "    conv_layer = conv2d_maxpool(x, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    conv_layer = flatten(conv_layer)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    num_outputs = 10\n",
    "    conv_layer = fully_conn(conv_layer, num_outputs)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    num_classes = 10\n",
    "    conv_layer = output(conv_layer, num_classes)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return conv_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "    print('Loss: {:>10.4f} Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "keep_probability = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2889 Accuracy: 0.176600\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.2921 Accuracy: 0.207600\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.2796 Accuracy: 0.215200\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.2641 Accuracy: 0.217800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     2.2354 Accuracy: 0.225000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     2.2033 Accuracy: 0.236400\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     2.1698 Accuracy: 0.249200\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     2.1310 Accuracy: 0.268400\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     2.0925 Accuracy: 0.293600\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     2.0588 Accuracy: 0.308400\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     2.0222 Accuracy: 0.330400\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.9836 Accuracy: 0.339400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.9462 Accuracy: 0.350200\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.9072 Accuracy: 0.361600\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.8769 Accuracy: 0.366200\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.8475 Accuracy: 0.368800\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.8163 Accuracy: 0.375400\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.7928 Accuracy: 0.378400\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.7659 Accuracy: 0.381400\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.7407 Accuracy: 0.383200\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.7198 Accuracy: 0.385000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.6975 Accuracy: 0.386000\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.6767 Accuracy: 0.387400\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.6559 Accuracy: 0.387800\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.6376 Accuracy: 0.388600\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.6202 Accuracy: 0.390600\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.6020 Accuracy: 0.392200\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.5810 Accuracy: 0.395000\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.5646 Accuracy: 0.392800\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.5471 Accuracy: 0.394400\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     1.5312 Accuracy: 0.397600\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.5164 Accuracy: 0.399400\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.5018 Accuracy: 0.399800\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.4879 Accuracy: 0.400200\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.4758 Accuracy: 0.400800\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.4633 Accuracy: 0.400400\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.4516 Accuracy: 0.401400\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.4396 Accuracy: 0.402600\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.4282 Accuracy: 0.404000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.4169 Accuracy: 0.404800\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.4069 Accuracy: 0.406800\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.3957 Accuracy: 0.407400\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.3857 Accuracy: 0.408400\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.3758 Accuracy: 0.408000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.3662 Accuracy: 0.409600\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.3563 Accuracy: 0.409800\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.3475 Accuracy: 0.410400\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.3398 Accuracy: 0.410000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.3302 Accuracy: 0.410600\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.3215 Accuracy: 0.410600\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.3130 Accuracy: 0.411600\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.3049 Accuracy: 0.413000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.2959 Accuracy: 0.413000\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.2869 Accuracy: 0.412800\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.2789 Accuracy: 0.412200\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.2711 Accuracy: 0.413400\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.2638 Accuracy: 0.413200\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.2564 Accuracy: 0.413400\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.2490 Accuracy: 0.413400\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.2419 Accuracy: 0.415000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.2350 Accuracy: 0.414800\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.2286 Accuracy: 0.415400\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.2220 Accuracy: 0.417000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.2149 Accuracy: 0.418200\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.2085 Accuracy: 0.418600\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.2020 Accuracy: 0.420400\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.1955 Accuracy: 0.421600\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.1901 Accuracy: 0.422400\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.1848 Accuracy: 0.423200\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.1795 Accuracy: 0.423800\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.1746 Accuracy: 0.424400\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.1698 Accuracy: 0.424800\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.1645 Accuracy: 0.426400\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.1591 Accuracy: 0.426800\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.1545 Accuracy: 0.428600\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.1489 Accuracy: 0.429200\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.1438 Accuracy: 0.430000\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.1386 Accuracy: 0.431200\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.1337 Accuracy: 0.430800\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.1283 Accuracy: 0.431600\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.1248 Accuracy: 0.431200\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.1198 Accuracy: 0.431800\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.1146 Accuracy: 0.432400\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.1099 Accuracy: 0.433800\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.1059 Accuracy: 0.434200\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.1012 Accuracy: 0.435000\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.0972 Accuracy: 0.436000\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.0932 Accuracy: 0.435600\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.0893 Accuracy: 0.436600\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.0855 Accuracy: 0.436200\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.0819 Accuracy: 0.436800\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.0779 Accuracy: 0.436800\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.0742 Accuracy: 0.436600\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.0710 Accuracy: 0.436000\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.0675 Accuracy: 0.436800\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.0638 Accuracy: 0.436600\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.0605 Accuracy: 0.437600\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.0570 Accuracy: 0.438200\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.0537 Accuracy: 0.438400\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     1.0504 Accuracy: 0.438800\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3132 Accuracy: 0.188600\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.1482 Accuracy: 0.217600\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     2.0624 Accuracy: 0.243200\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     2.0247 Accuracy: 0.248200\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     2.0147 Accuracy: 0.275800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.2152 Accuracy: 0.281200\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.8937 Accuracy: 0.300000\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.7888 Accuracy: 0.320200\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.8190 Accuracy: 0.316800\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.8558 Accuracy: 0.333800\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.0746 Accuracy: 0.357600\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.6814 Accuracy: 0.378400\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.6008 Accuracy: 0.385000\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.6722 Accuracy: 0.378600\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.7148 Accuracy: 0.384600\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.9897 Accuracy: 0.396000\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.5266 Accuracy: 0.414600\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     1.4601 Accuracy: 0.418000\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.6010 Accuracy: 0.408000\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.6073 Accuracy: 0.411400\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.9175 Accuracy: 0.425400\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.4216 Accuracy: 0.434800\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     1.3714 Accuracy: 0.434400\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     1.5623 Accuracy: 0.434200\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.5272 Accuracy: 0.432600\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.8535 Accuracy: 0.444600\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.3413 Accuracy: 0.443400\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     1.3150 Accuracy: 0.445400\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     1.5374 Accuracy: 0.448400\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.4769 Accuracy: 0.440600\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.7994 Accuracy: 0.447600\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.2855 Accuracy: 0.451000\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     1.2728 Accuracy: 0.451200\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     1.5155 Accuracy: 0.460000\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     1.4327 Accuracy: 0.450200\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.7642 Accuracy: 0.455000\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     1.2439 Accuracy: 0.453800\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.2411 Accuracy: 0.457600\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.4983 Accuracy: 0.471000\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     1.3905 Accuracy: 0.456600\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.7360 Accuracy: 0.466200\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.2086 Accuracy: 0.456600\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     1.2144 Accuracy: 0.466800\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     1.4749 Accuracy: 0.475200\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     1.3590 Accuracy: 0.461600\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.7132 Accuracy: 0.472400\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.1783 Accuracy: 0.462200\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.1938 Accuracy: 0.470000\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.4573 Accuracy: 0.482400\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     1.3381 Accuracy: 0.470200\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.6973 Accuracy: 0.477200\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     1.1506 Accuracy: 0.469800\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     1.1736 Accuracy: 0.472200\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     1.4375 Accuracy: 0.486400\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     1.3220 Accuracy: 0.474800\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.6798 Accuracy: 0.477200\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     1.1264 Accuracy: 0.475800\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     1.1549 Accuracy: 0.475400\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     1.4159 Accuracy: 0.488400\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     1.3094 Accuracy: 0.476000\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.6659 Accuracy: 0.480600\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     1.1040 Accuracy: 0.480000\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     1.1383 Accuracy: 0.480000\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     1.3930 Accuracy: 0.491800\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     1.2978 Accuracy: 0.480400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.6515 Accuracy: 0.484600\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     1.0855 Accuracy: 0.484800\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     1.1210 Accuracy: 0.483000\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     1.3716 Accuracy: 0.493200\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     1.2892 Accuracy: 0.483400\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.6396 Accuracy: 0.488400\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     1.0705 Accuracy: 0.485000\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     1.1039 Accuracy: 0.487400\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     1.3537 Accuracy: 0.494600\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     1.2814 Accuracy: 0.486200\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.6267 Accuracy: 0.488400\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     1.0557 Accuracy: 0.487800\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     1.0899 Accuracy: 0.490200\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     1.3364 Accuracy: 0.497200\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     1.2749 Accuracy: 0.487400\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.6168 Accuracy: 0.490600\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     1.0453 Accuracy: 0.489000\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     1.0760 Accuracy: 0.492400\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     1.3193 Accuracy: 0.500200\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     1.2694 Accuracy: 0.492800\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.6073 Accuracy: 0.489400\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     1.0364 Accuracy: 0.490000\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     1.0634 Accuracy: 0.496200\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     1.3034 Accuracy: 0.501800\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     1.2650 Accuracy: 0.497000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.6020 Accuracy: 0.495200\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     1.0284 Accuracy: 0.492600\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     1.0524 Accuracy: 0.500400\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     1.2888 Accuracy: 0.502000\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     1.2592 Accuracy: 0.499600\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.5915 Accuracy: 0.497400\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     1.0204 Accuracy: 0.494200\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     1.0412 Accuracy: 0.502400\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     1.2762 Accuracy: 0.504600\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     1.2516 Accuracy: 0.500400\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.5835 Accuracy: 0.505000\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     1.0111 Accuracy: 0.498600\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     1.0320 Accuracy: 0.505800\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     1.2635 Accuracy: 0.507800\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     1.2449 Accuracy: 0.503400\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.5779 Accuracy: 0.508200\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     1.0046 Accuracy: 0.503400\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     1.0235 Accuracy: 0.507000\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     1.2519 Accuracy: 0.507600\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     1.2376 Accuracy: 0.506200\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.5702 Accuracy: 0.511400\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     0.9981 Accuracy: 0.501600\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     1.0167 Accuracy: 0.509600\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     1.2422 Accuracy: 0.509000\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     1.2316 Accuracy: 0.505800\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.5633 Accuracy: 0.513600\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     0.9926 Accuracy: 0.503400\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     1.0094 Accuracy: 0.511600\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     1.2314 Accuracy: 0.509600\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     1.2258 Accuracy: 0.507400\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.5574 Accuracy: 0.516000\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     0.9874 Accuracy: 0.506600\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     1.0019 Accuracy: 0.514600\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     1.2213 Accuracy: 0.511600\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     1.2188 Accuracy: 0.508400\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.5506 Accuracy: 0.516000\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     0.9817 Accuracy: 0.508400\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     0.9949 Accuracy: 0.515000\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     1.2119 Accuracy: 0.514000\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     1.2120 Accuracy: 0.512200\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.5442 Accuracy: 0.516400\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     0.9765 Accuracy: 0.509800\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     0.9879 Accuracy: 0.516800\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     1.2036 Accuracy: 0.515600\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     1.2039 Accuracy: 0.513000\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.5389 Accuracy: 0.519400\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     0.9725 Accuracy: 0.511200\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     0.9807 Accuracy: 0.518800\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     1.1943 Accuracy: 0.519200\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     1.1975 Accuracy: 0.514200\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.5347 Accuracy: 0.521400\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     0.9662 Accuracy: 0.512800\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     0.9742 Accuracy: 0.520600\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     1.1872 Accuracy: 0.519600\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     1.1895 Accuracy: 0.516000\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.5297 Accuracy: 0.522200\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     0.9611 Accuracy: 0.514000\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     0.9691 Accuracy: 0.522800\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     1.1797 Accuracy: 0.520600\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     1.1823 Accuracy: 0.516800\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     1.5247 Accuracy: 0.523000\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     0.9554 Accuracy: 0.516000\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     0.9641 Accuracy: 0.523000\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     1.1716 Accuracy: 0.523000\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     1.1765 Accuracy: 0.517200\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.5203 Accuracy: 0.525000\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     0.9498 Accuracy: 0.517200\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     0.9590 Accuracy: 0.524000\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     1.1639 Accuracy: 0.524800\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     1.1700 Accuracy: 0.517800\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.5163 Accuracy: 0.523800\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     0.9450 Accuracy: 0.517600\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     0.9544 Accuracy: 0.526000\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     1.1566 Accuracy: 0.525200\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     1.1626 Accuracy: 0.519000\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.5132 Accuracy: 0.524600\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     0.9405 Accuracy: 0.518000\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     0.9484 Accuracy: 0.527000\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     1.1493 Accuracy: 0.526600\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     1.1567 Accuracy: 0.518800\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.5103 Accuracy: 0.526400\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     0.9356 Accuracy: 0.519200\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     0.9435 Accuracy: 0.531600\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     1.1421 Accuracy: 0.528000\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     1.1512 Accuracy: 0.522400\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.5075 Accuracy: 0.527200\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     0.9303 Accuracy: 0.520200\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     0.9373 Accuracy: 0.532600\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     1.1357 Accuracy: 0.530800\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     1.1453 Accuracy: 0.524000\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.5033 Accuracy: 0.527800\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     0.9255 Accuracy: 0.521800\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     0.9332 Accuracy: 0.533600\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     1.1299 Accuracy: 0.530600\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     1.1397 Accuracy: 0.525400\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.4989 Accuracy: 0.529800\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     0.9216 Accuracy: 0.523000\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     0.9294 Accuracy: 0.533600\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     1.1246 Accuracy: 0.532200\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     1.1333 Accuracy: 0.525200\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.4944 Accuracy: 0.530400\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     0.9175 Accuracy: 0.523200\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     0.9261 Accuracy: 0.533800\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     1.1188 Accuracy: 0.533400\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     1.1273 Accuracy: 0.526600\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.4913 Accuracy: 0.531200\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     0.9135 Accuracy: 0.523600\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     0.9224 Accuracy: 0.534800\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     1.1141 Accuracy: 0.533000\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     1.1222 Accuracy: 0.525200\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.4872 Accuracy: 0.533800\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     0.9102 Accuracy: 0.526000\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     0.9188 Accuracy: 0.535400\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     1.1092 Accuracy: 0.534400\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     1.1161 Accuracy: 0.526600\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.4824 Accuracy: 0.535200\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     0.9074 Accuracy: 0.526800\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     0.9143 Accuracy: 0.536600\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     1.1047 Accuracy: 0.533000\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     1.1114 Accuracy: 0.527600\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.4784 Accuracy: 0.537000\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     0.9045 Accuracy: 0.527200\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     0.9100 Accuracy: 0.538200\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     1.1002 Accuracy: 0.534600\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     1.1067 Accuracy: 0.527400\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.4733 Accuracy: 0.537800\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     0.9010 Accuracy: 0.527000\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     0.9067 Accuracy: 0.539200\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     1.0967 Accuracy: 0.535200\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     1.1015 Accuracy: 0.527800\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.4683 Accuracy: 0.537000\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     0.8980 Accuracy: 0.526800\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     0.9030 Accuracy: 0.539400\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     1.0932 Accuracy: 0.536600\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     1.0963 Accuracy: 0.527000\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.4627 Accuracy: 0.537600\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     0.8948 Accuracy: 0.527400\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     0.8991 Accuracy: 0.540400\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     1.0898 Accuracy: 0.537200\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     1.0921 Accuracy: 0.527000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.4571 Accuracy: 0.538000\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     0.8917 Accuracy: 0.528000\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     0.8961 Accuracy: 0.541000\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     1.0864 Accuracy: 0.537200\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     1.0877 Accuracy: 0.528400\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.4530 Accuracy: 0.537800\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     0.8883 Accuracy: 0.529400\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     0.8929 Accuracy: 0.542200\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     1.0838 Accuracy: 0.537200\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     1.0825 Accuracy: 0.529200\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.4473 Accuracy: 0.538200\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     0.8847 Accuracy: 0.529800\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     0.8897 Accuracy: 0.540200\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     1.0809 Accuracy: 0.537000\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     1.0776 Accuracy: 0.530400\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.4418 Accuracy: 0.539000\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     0.8819 Accuracy: 0.530400\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     0.8869 Accuracy: 0.540800\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     1.0781 Accuracy: 0.538000\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     1.0735 Accuracy: 0.529200\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.4367 Accuracy: 0.537600\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     0.8792 Accuracy: 0.530800\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     0.8850 Accuracy: 0.543000\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     1.0761 Accuracy: 0.537800\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     1.0690 Accuracy: 0.531800\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.4322 Accuracy: 0.537800\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     0.8769 Accuracy: 0.530600\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     0.8830 Accuracy: 0.542200\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     1.0740 Accuracy: 0.539200\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     1.0644 Accuracy: 0.532000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.4277 Accuracy: 0.538600\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     0.8747 Accuracy: 0.532200\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     0.8807 Accuracy: 0.543400\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     1.0720 Accuracy: 0.540000\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     1.0606 Accuracy: 0.533200\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.4232 Accuracy: 0.538000\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     0.8727 Accuracy: 0.533600\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     0.8792 Accuracy: 0.543800\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     1.0705 Accuracy: 0.540000\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     1.0563 Accuracy: 0.533400\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.4165 Accuracy: 0.538200\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     0.8691 Accuracy: 0.534400\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     0.8773 Accuracy: 0.544600\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     1.0696 Accuracy: 0.542000\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     1.0526 Accuracy: 0.534800\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.4113 Accuracy: 0.538800\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     0.8669 Accuracy: 0.535000\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     0.8758 Accuracy: 0.545000\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     1.0687 Accuracy: 0.543000\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     1.0478 Accuracy: 0.534400\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.4058 Accuracy: 0.539600\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     0.8641 Accuracy: 0.535200\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     0.8744 Accuracy: 0.546000\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     1.0673 Accuracy: 0.542800\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     1.0441 Accuracy: 0.535000\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.4010 Accuracy: 0.540200\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     0.8618 Accuracy: 0.534200\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     0.8726 Accuracy: 0.546800\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     1.0662 Accuracy: 0.543400\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     1.0400 Accuracy: 0.534000\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.3956 Accuracy: 0.539800\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     0.8601 Accuracy: 0.534800\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     0.8704 Accuracy: 0.547200\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     1.0649 Accuracy: 0.544000\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     1.0361 Accuracy: 0.533400\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.3921 Accuracy: 0.541600\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     0.8579 Accuracy: 0.535800\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     0.8689 Accuracy: 0.547600\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     1.0634 Accuracy: 0.545400\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     1.0316 Accuracy: 0.532800\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.3868 Accuracy: 0.542800\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     0.8560 Accuracy: 0.537400\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     0.8673 Accuracy: 0.546600\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     1.0618 Accuracy: 0.544800\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     1.0272 Accuracy: 0.533600\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.3830 Accuracy: 0.541200\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     0.8537 Accuracy: 0.537600\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     0.8657 Accuracy: 0.546600\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     1.0605 Accuracy: 0.546200\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     1.0231 Accuracy: 0.534200\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.3784 Accuracy: 0.541200\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     0.8514 Accuracy: 0.538000\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     0.8645 Accuracy: 0.546000\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     1.0594 Accuracy: 0.547800\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     1.0196 Accuracy: 0.535000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.3749 Accuracy: 0.541400\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     0.8488 Accuracy: 0.538200\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     0.8636 Accuracy: 0.547600\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     1.0579 Accuracy: 0.548000\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     1.0169 Accuracy: 0.535800\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.3712 Accuracy: 0.543600\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     0.8467 Accuracy: 0.537400\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     0.8625 Accuracy: 0.547200\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     1.0568 Accuracy: 0.548800\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     1.0129 Accuracy: 0.535000\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.3680 Accuracy: 0.545000\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     0.8445 Accuracy: 0.538000\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     0.8617 Accuracy: 0.547400\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     1.0557 Accuracy: 0.550400\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     1.0089 Accuracy: 0.535000\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.3649 Accuracy: 0.545000\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     0.8422 Accuracy: 0.538000\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     0.8606 Accuracy: 0.548200\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     1.0549 Accuracy: 0.550800\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     1.0057 Accuracy: 0.535600\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.3621 Accuracy: 0.545400\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     0.8397 Accuracy: 0.539000\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     0.8593 Accuracy: 0.548800\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     1.0537 Accuracy: 0.549800\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     1.0022 Accuracy: 0.536200\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.3583 Accuracy: 0.546400\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     0.8374 Accuracy: 0.540000\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     0.8583 Accuracy: 0.549400\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     1.0529 Accuracy: 0.549400\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     0.9999 Accuracy: 0.536200\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.3546 Accuracy: 0.546400\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     0.8354 Accuracy: 0.540400\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     0.8577 Accuracy: 0.549000\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     1.0522 Accuracy: 0.550600\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     0.9965 Accuracy: 0.536600\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.3517 Accuracy: 0.547600\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:     0.8334 Accuracy: 0.542200\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:     0.8563 Accuracy: 0.548400\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:     1.0515 Accuracy: 0.549600\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:     0.9933 Accuracy: 0.537600\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.3486 Accuracy: 0.546800\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:     0.8311 Accuracy: 0.542600\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:     0.8557 Accuracy: 0.548400\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:     1.0505 Accuracy: 0.549800\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:     0.9904 Accuracy: 0.538400\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.3463 Accuracy: 0.547600\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:     0.8289 Accuracy: 0.544200\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:     0.8546 Accuracy: 0.548800\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:     1.0498 Accuracy: 0.550000\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:     0.9879 Accuracy: 0.538600\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.3447 Accuracy: 0.547200\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:     0.8268 Accuracy: 0.543800\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:     0.8534 Accuracy: 0.549800\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:     1.0492 Accuracy: 0.549800\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:     0.9845 Accuracy: 0.538000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.3415 Accuracy: 0.547800\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:     0.8248 Accuracy: 0.544000\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:     0.8524 Accuracy: 0.549800\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:     1.0487 Accuracy: 0.550000\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:     0.9818 Accuracy: 0.538200\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.3377 Accuracy: 0.547800\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:     0.8224 Accuracy: 0.544800\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:     0.8518 Accuracy: 0.549600\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:     1.0477 Accuracy: 0.549400\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:     0.9789 Accuracy: 0.539200\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.3356 Accuracy: 0.548000\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:     0.8209 Accuracy: 0.545400\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:     0.8515 Accuracy: 0.550200\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:     1.0463 Accuracy: 0.549200\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:     0.9763 Accuracy: 0.539800\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.3328 Accuracy: 0.547600\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:     0.8188 Accuracy: 0.544800\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:     0.8500 Accuracy: 0.550600\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:     1.0450 Accuracy: 0.550600\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:     0.9742 Accuracy: 0.539200\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.3305 Accuracy: 0.548400\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:     0.8168 Accuracy: 0.545400\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:     0.8499 Accuracy: 0.551400\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:     1.0447 Accuracy: 0.550200\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:     0.9721 Accuracy: 0.539800\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.3279 Accuracy: 0.548200\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:     0.8150 Accuracy: 0.544600\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:     0.8491 Accuracy: 0.551400\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:     1.0438 Accuracy: 0.550800\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:     0.9693 Accuracy: 0.540200\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.3256 Accuracy: 0.547600\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:     0.8137 Accuracy: 0.545000\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:     0.8494 Accuracy: 0.551000\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:     1.0430 Accuracy: 0.552200\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:     0.9668 Accuracy: 0.540600\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.3228 Accuracy: 0.548200\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:     0.8118 Accuracy: 0.544800\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:     0.8482 Accuracy: 0.551000\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:     1.0423 Accuracy: 0.552400\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:     0.9647 Accuracy: 0.541600\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.3208 Accuracy: 0.549000\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:     0.8103 Accuracy: 0.545400\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:     0.8476 Accuracy: 0.551000\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:     1.0417 Accuracy: 0.552200\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:     0.9625 Accuracy: 0.540600\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.3181 Accuracy: 0.547000\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:     0.8088 Accuracy: 0.545800\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:     0.8473 Accuracy: 0.550600\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:     1.0417 Accuracy: 0.553600\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:     0.9603 Accuracy: 0.542600\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.3165 Accuracy: 0.546600\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:     0.8068 Accuracy: 0.545200\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:     0.8461 Accuracy: 0.550000\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:     1.0413 Accuracy: 0.552800\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:     0.9582 Accuracy: 0.543600\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.3142 Accuracy: 0.546000\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:     0.8052 Accuracy: 0.545600\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:     0.8451 Accuracy: 0.550800\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:     1.0408 Accuracy: 0.552800\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:     0.9563 Accuracy: 0.543400\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.3118 Accuracy: 0.546400\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:     0.8037 Accuracy: 0.546600\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:     0.8448 Accuracy: 0.551000\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:     1.0406 Accuracy: 0.552600\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:     0.9542 Accuracy: 0.543200\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.3090 Accuracy: 0.546600\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:     0.8018 Accuracy: 0.545400\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:     0.8445 Accuracy: 0.551000\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:     1.0398 Accuracy: 0.553200\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:     0.9525 Accuracy: 0.543800\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.3063 Accuracy: 0.547400\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:     0.8006 Accuracy: 0.546800\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:     0.8443 Accuracy: 0.552200\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:     1.0398 Accuracy: 0.553400\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:     0.9504 Accuracy: 0.544000\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.3052 Accuracy: 0.547600\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:     0.7985 Accuracy: 0.546600\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:     0.8438 Accuracy: 0.552600\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:     1.0400 Accuracy: 0.553200\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:     0.9485 Accuracy: 0.544600\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.3028 Accuracy: 0.548000\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:     0.7969 Accuracy: 0.545200\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:     0.8436 Accuracy: 0.552600\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:     1.0402 Accuracy: 0.552800\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:     0.9463 Accuracy: 0.544400\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.3012 Accuracy: 0.548600\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:     0.7954 Accuracy: 0.545400\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:     0.8432 Accuracy: 0.551800\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:     1.0400 Accuracy: 0.553000\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:     0.9444 Accuracy: 0.545000\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.2993 Accuracy: 0.548600\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:     0.7939 Accuracy: 0.545800\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:     0.8432 Accuracy: 0.552200\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:     1.0401 Accuracy: 0.553600\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:     0.9420 Accuracy: 0.545800\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.2981 Accuracy: 0.548200\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:     0.7918 Accuracy: 0.546400\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:     0.8434 Accuracy: 0.552800\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:     1.0399 Accuracy: 0.553200\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:     0.9404 Accuracy: 0.545400\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.2958 Accuracy: 0.548800\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:     0.7904 Accuracy: 0.546200\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:     0.8429 Accuracy: 0.552600\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:     1.0395 Accuracy: 0.553400\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:     0.9389 Accuracy: 0.546800\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.2944 Accuracy: 0.548400\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:     0.7893 Accuracy: 0.546200\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:     0.8425 Accuracy: 0.552800\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:     1.0396 Accuracy: 0.554000\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:     0.9372 Accuracy: 0.547000\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.2927 Accuracy: 0.548000\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:     0.7880 Accuracy: 0.547000\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:     0.8422 Accuracy: 0.554200\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:     1.0396 Accuracy: 0.554000\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:     0.9355 Accuracy: 0.547800\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.2911 Accuracy: 0.548800\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:     0.7865 Accuracy: 0.547400\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:     0.8422 Accuracy: 0.553800\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:     1.0398 Accuracy: 0.553400\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:     0.9336 Accuracy: 0.548000\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.2895 Accuracy: 0.548800\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:     0.7851 Accuracy: 0.547000\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:     0.8419 Accuracy: 0.554600\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:     1.0395 Accuracy: 0.553600\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:     0.9321 Accuracy: 0.548400\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     1.2874 Accuracy: 0.549000\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:     0.7840 Accuracy: 0.547200\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:     0.8413 Accuracy: 0.554200\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:     1.0396 Accuracy: 0.553600\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:     0.9303 Accuracy: 0.548400\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.5505859375\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCghYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe4b8019b70>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
